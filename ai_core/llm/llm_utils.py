# llm_utils.py
import os
from openai import OpenAI
import google.generativeai as genai
from dotenv import load_dotenv

# âœ… .env ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# âœ… í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

google_api_key = os.getenv("GOOGLE_API_KEY")
if not google_api_key:
    raise ValueError("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")

# âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=api_key)

# âœ… Google AI ì´ˆê¸°í™”
genai.configure(api_key=google_api_key)


# ğŸ”¹ ì„ë² ë”© í•¨ìˆ˜ (Google ì„ë² ë”© ì‚¬ìš© - ë²¡í„° DBì™€ ë™ì¼í•œ ëª¨ë¸)
def get_embedding(text):
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="RETRIEVAL_QUERY"
        )
        return result['embedding']
    except Exception as e:
        print(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# ğŸ”¹ ê°ì • ì¶”ì¶œ í•¨ìˆ˜
def extract_emotion(user_input: str) -> str:
    prompt = f"""
    ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê°€ì¥ ë‘ë“œëŸ¬ì§€ëŠ” í•µì‹¬ ê°ì • í•œ ê°€ì§€ë¥¼
    'í–‰ë³µ', 'ìŠ¬í””', 'ë¶„ë…¸', 'í‰ì˜¨', 'ë¶ˆì•ˆ' ì¤‘ì—ì„œ í•˜ë‚˜ë§Œ ê³¨ë¼ì£¼ì„¸ìš”.
    ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ê°ì • ë‹¨ì–´ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

    ë¬¸ì¥: "{user_input}"
    ê°ì •:
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ê°ì • ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "í‰ì˜¨"


# ğŸ”¹ ì „ì²´ ëŒ€í™”ì—ì„œ ìµœê·¼ ê°ì • ì¶”ì¶œ í•¨ìˆ˜ (ê°œì„  ë²„ì „)
def extract_recent_emotion(conversation_history: str) -> str:
    """
    ëŒ€í™” ì „ì²´ë¥¼ ë¶„ì„í•˜ë˜, ì—¬ëŸ¬ ê°ì •ì´ ìˆì„ ê²½ìš° ê°€ì¥ ìµœê·¼ ê°ì •ì„ ì„ íƒí•©ë‹ˆë‹¤.
    ì§§ì€ ì¸ì‚¬ë§ì´ë‚˜ ê°„ë‹¨í•œ ì‘ë‹µì€ ë¬´ì‹œí•©ë‹ˆë‹¤.
    """
    # ëŒ€í™” ë‚´ì—­ì´ ë¹„ì–´ìˆê±°ë‚˜ ë„ˆë¬´ ì§§ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
    if not conversation_history or len(conversation_history.strip()) < 5:
        return "í‰ì˜¨"

    prompt = f"""
    ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì‘ì„±í•œ ëŒ€í™” ë‚´ì—­ì…ë‹ˆë‹¤.
    ì „ì²´ ëŒ€í™”ë¥¼ ì½ê³ , ê°€ì¥ ìµœê·¼ì— í‘œí˜„ëœ ê°ì •ì„ íŒŒì•…í•´ì£¼ì„¸ìš”.

    ì¤‘ìš”í•œ ê·œì¹™:
    1. "ê³ ë§ˆì›Œ", "ê°ì‚¬", "ã…‹ã…‹", "ã…ã…" ê°™ì€ ì§§ì€ ì¸ì‚¬ë§ì´ë‚˜ ë°˜ì‘ì€ ë¬´ì‹œí•˜ì„¸ìš”.
    2. ì‹¤ì œ ê°ì •ì´ ë‹´ê¸´ ì˜ë¯¸ ìˆëŠ” ë¬¸ì¥ë§Œ ë¶„ì„í•˜ì„¸ìš”.
    3. ì—¬ëŸ¬ ê°ì •ì´ ì„ì—¬ ìˆë‹¤ë©´, ì‹œê°„ ìˆœì„œìƒ ê°€ì¥ ë§ˆì§€ë§‰ì— ë‚˜íƒ€ë‚œ ê°ì •ì„ ì„ íƒí•˜ì„¸ìš”.
    4. 'í–‰ë³µ', 'ìŠ¬í””', 'ë¶„ë…¸', 'í‰ì˜¨', 'ë¶ˆì•ˆ' ì¤‘ì—ì„œ í•˜ë‚˜ë§Œ ê³¨ë¼ì£¼ì„¸ìš”.
    5. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ê°ì • ë‹¨ì–´ë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.

    ëŒ€í™” ë‚´ì—­:
    {conversation_history}

    ê°€ì¥ ìµœê·¼ ê°ì •:
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3  # ë” ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ temperature
        )
        emotion = response.choices[0].message.content.strip()
        # ìœ íš¨í•œ ê°ì •ì¸ì§€ í™•ì¸
        valid_emotions = ["í–‰ë³µ", "ìŠ¬í””", "ë¶„ë…¸", "í‰ì˜¨", "ë¶ˆì•ˆ"]
        if emotion in valid_emotions:
            return emotion
        return "í‰ì˜¨"
    except Exception as e:
        print(f"ìµœê·¼ ê°ì • ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "í‰ì˜¨"


# ğŸ”¹ ìœ„ë¡œ ë©”ì‹œì§€ ìƒì„± í•¨ìˆ˜
def generate_comforting_message(user_emotion: str, content: dict) -> str:
    content_type = list(content.keys())[0]
    content_name = content[content_type]

    prompt = f"""
    ì‚¬ìš©ìëŠ” í˜„ì¬ '{user_emotion}'ì˜ ê°ì •ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.
    ì´ ì‚¬ìš©ìì—ê²Œ ë”°ëœ»í•œ ìœ„ë¡œì™€ ê³µê°ì˜ ë§ì„ ì „í•´ì£¼ì„¸ìš”.
    ê·¸ë¦¬ê³  ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ê³¼ ë‹¤ë¥¸ ìƒˆë¡œìš´ ê²½í—˜ì„ í•  ìˆ˜ ìˆë„ë¡,
    '{content_name}'({content_type})ì„(ë¥¼) ì¶”ì²œí•´ì£¼ì„¸ìš”.
    ì¶”ì²œí•˜ëŠ” ì´ìœ ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•˜ë©° ë©”ì‹œì§€ë¥¼ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.
    ì‘ë‹µì€ í•œêµ­ì–´ë¡œ, ì¹œê·¼í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê´œì°®ì•„ìš”, ëª¨ë“  ê²Œ ë‹¤ ì˜ ë  ê±°ì˜ˆìš”. ì˜¤ëŠ˜ í•˜ë£¨ë„ ì •ë§ ê³ ìƒ ë§ìœ¼ì…¨ì–´ìš”."


# ğŸ”¹ ìºë¦­í„°ë³„ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_character_response(character: str, user_emotion: str, content: dict) -> str:
    """
    ìºë¦­í„° ë§íˆ¬ë¥¼ ë°˜ì˜í•œ ìœ„ë¡œ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from prompt.characters import get_character_prompt

    # ì½˜í…ì¸  ì •ë³´ ì¶”ì¶œ
    if "error" in content:
        content_description = "ì¶”ì²œí•  ì½˜í…ì¸ ê°€ ì—†ì–´ìš”."
    else:
        content_type = list(content.keys())[0]
        content_name = content[content_type]
        content_description = f"{content_name} ({content_type})"

    # ìºë¦­í„° í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    character_prompt = get_character_prompt(character)

    # ì „ì²´ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = character_prompt
    user_prompt = f"""
    ì‚¬ìš©ìëŠ” í˜„ì¬ '{user_emotion}'ì˜ ê°ì •ì„ ëŠë¼ê³  ìˆìŠµë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ìºë¦­í„°ì— ë§ëŠ” ë§íˆ¬ë¡œ ì‚¬ìš©ìë¥¼ ë”°ëœ»í•˜ê²Œ ìœ„ë¡œí•˜ê³ ,
    '{content_description}'ì„(ë¥¼) ì¶”ì²œí•´ì£¼ì„¸ìš”.

    ìºë¦­í„°ì˜ íŠ¹ì§•ì„ ì˜ ì‚´ë ¤ì„œ ìì—°ìŠ¤ëŸ½ê³  ì§„ì •ì„± ìˆëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
    ì‘ë‹µì€ í•œêµ­ì–´ë¡œ 3-5ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ìºë¦­í„° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê´œì°®ì•„ìš”, ëª¨ë“  ê²Œ ë‹¤ ì˜ ë  ê±°ì˜ˆìš”. ì˜¤ëŠ˜ í•˜ë£¨ë„ ì •ë§ ê³ ìƒ ë§ìœ¼ì…¨ì–´ìš”."


# ğŸ”¹ ê³µê° ê¸°ëŠ¥ ê°•í™”ëœ ì‘ë‹µ í•¨ìˆ˜
def generate_empathetic_response(character: str, user_sentence: str, user_emotion: str) -> str:
    """
    ì‚¬ìš©ìì˜ ë§ì— ê¹Šì´ ê³µê°í•˜ëŠ” ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from prompt.characters import get_character_prompt

    # ìºë¦­í„° í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    character_prompt = get_character_prompt(character)

    # ê³µê° ì¤‘ì‹¬ì˜ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    system_prompt = character_prompt + """

    ì¤‘ìš”í•œ ê·œì¹™:
    1. ì‚¬ìš©ìì˜ ê°ì •ì„ ë¨¼ì € ì¸ì •í•˜ê³  ê³µê°í•´ì£¼ì„¸ìš”
    2. ì‚¬ìš©ìì˜ ê²½í—˜ì„ ì†Œì¤‘í•˜ê²Œ ì—¬ê¸°ëŠ” íƒœë„ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”
    3. íŒë‹¨í•˜ì§€ ë§ê³ , ìˆëŠ” ê·¸ëŒ€ë¡œ ë°›ì•„ë“¤ì—¬ì£¼ì„¸ìš”
    4. ë”°ëœ»í•˜ê³  ì§„ì‹¬ ì–´ë¦° ìœ„ë¡œë¥¼ ì „í•´ì£¼ì„¸ìš”
    5. ìºë¦­í„°ì˜ ë§íˆ¬ë¥¼ ìœ ì§€í•˜ë©´ì„œë„ ì§„ì •ì„±ì„ ìƒì§€ ë§ˆì„¸ìš”
    """

    user_prompt = f"""
    ì‚¬ìš©ìê°€ ì´ë ‡ê²Œ ë§í–ˆìŠµë‹ˆë‹¤: "{user_sentence}"

    ê°ì • ë¶„ì„ ê²°ê³¼: {user_emotion}

    ë‹¹ì‹ ì˜ ìºë¦­í„° íŠ¹ì„±ì„ ì‚´ë ¤ì„œ, ì‚¬ìš©ìì—ê²Œ ì§„ì‹¬ìœ¼ë¡œ ê³µê°í•˜ê³  ìœ„ë¡œí•´ì£¼ì„¸ìš”.
    ì‚¬ìš©ìì˜ ê°ì •ì„ ì¶©ë¶„íˆ ì´í•´í•˜ê³  ìˆë‹¤ëŠ” ê²ƒì„ ë³´ì—¬ì£¼ë©°,
    ë”°ëœ»í•œ ë§ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.

    ì‘ë‹µì€ 3-5ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.8  # ë” ìì—°ìŠ¤ëŸ½ê³  ë‹¤ì–‘í•œ ì‘ë‹µì„ ìœ„í•´
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ê³µê° ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return "ê´œì°®ì•„ìš”, ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê³  ìˆì–´ìš”. í•¨ê»˜ ìˆì–´ì¤„ê²Œìš”."


# ğŸ”¹ ì¶”ì²œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_recommendation_response(character: str, category: str, recommendation_data: dict, formatted_recommendation: str) -> str:
    """
    RAG ê¸°ë°˜ ì¶”ì²œì„ ìºë¦­í„° ë§íˆ¬ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    """
    from prompt.characters import get_character_prompt

    # ìºë¦­í„° í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    character_prompt = get_character_prompt(character)

    # ê°ì • ì •ë³´ ì¶”ì¶œ
    current_emotion = recommendation_data.get("current_emotion", "")
    recommended_emotion = recommendation_data.get("recommended_emotion", "")

    system_prompt = character_prompt + """

    ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê°ì • ìƒíƒœë¥¼ íŒŒì•…í•˜ê³ , ê·¸ì— ë§ëŠ” ì¶”ì²œì„ í•´ì£¼ëŠ” ì—­í• ì…ë‹ˆë‹¤.
    ì¶”ì²œí•  ë•ŒëŠ”:
    1. ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •ì„ ë¨¼ì € ê³µê°í•´ì£¼ì„¸ìš”
    2. ì™œ ì´ ì¶”ì²œì´ ë„ì›€ì´ ë ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”
    3. ìºë¦­í„°ì˜ íŠ¹ì„±ì„ ì‚´ë ¤ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”
    """

    user_prompt = f"""
    ì‚¬ìš©ìì˜ í˜„ì¬ ê°ì •: {current_emotion}
    ì¶”ì²œ ì¹´í…Œê³ ë¦¬: {category}

    ë‹¤ìŒ ì¶”ì²œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ìºë¦­í„°ì˜ ë§íˆ¬ë¥¼ ì‚´ë ¤ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´ì£¼ì„¸ìš”:

    {formatted_recommendation}

    ì‚¬ìš©ìì—ê²Œ ì´ ì¶”ì²œì´ ì™œ ì¢‹ì€ì§€, ì–´ë–¤ ë„ì›€ì´ ë ì§€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”.
    ì‘ë‹µì€ 4-6ë¬¸ì¥ ì •ë„ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"ì¶”ì²œ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"{formatted_recommendation}\n\nì´ ì¶”ì²œì´ ë„ì›€ì´ ë˜ì—ˆìœ¼ë©´ ì¢‹ê² ì–´ìš”!"


# ğŸ”¹ ê°„ë‹¨ ì‘ë‹µ í•¨ìˆ˜
def get_llm_answer(user_sentence: str) -> str:
    try:
        prompt = f"ë‹¤ìŒ ë¬¸ì¥ì— ëŒ€í•´ ê³µê°í•˜ê³  ì§§ê²Œ ë‹µí•´ì£¼ì„¸ìš”(í•œêµ­ì–´): \"{user_sentence}\""
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return "ì ì‹œ ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
